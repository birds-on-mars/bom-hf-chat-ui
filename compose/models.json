[
    {
        "name": "gpt-4-turbo-preview",
        "displayName": "OpenAI GPT-4 Turbo (preview)",
        "description": "OpenAI GPT-4 Turbo (preview), temperature: 0.2",
        "parameters": {
            "temperature": 0.2,
            "max_new_tokens": 1024
        },
        "endpoints": [
            {
                "type": "openai"
            }
        ]
    },
    {
        "name": "gpt-3.5-turbo",
        "displayName": "OpenAI GPT-3.5 Turbo, temperature: 0.2",
        "description": "OpenAI GPT-3.5 Turbo",
        "parameters": {
            "temperature": 0.2,
            "max_new_tokens": 1024
        },
        "endpoints": [
            {
                "type": "openai"
            }
        ]
    },
    {
        "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "displayName": "ü§ó Mixtral 8x7B Instruct",
        "description": "The latest MoE model from Mistral AI! 8x7B and outperforms Llama 2 70B in most benchmarks.",
        "websiteUrl": "https://mistral.ai/news/mixtral-of-experts/",
        "preprompt": "",
        "chatPromptTemplate": "<s> {{#each messages}}{{#ifUser}}[INST]{{#if @first}}{{#if @root.preprompt}}{{@root.preprompt}}\n{{/if}}{{/if}} {{content}} [/INST]{{/ifUser}}{{#ifAssistant}} {{content}}</s> {{/ifAssistant}}{{/each}}",
        "parameters": {
            "temperature": 0.6,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "top_k": 50,
            "truncate": 24576,
            "max_new_tokens": 8192,
            "stop": [
                "</s>"
            ]
        },
        "promptExamples": [
            {
                "title": "Write an email from bullet list",
                "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
            },
            {
                "title": "Code a snake game",
                "prompt": "Code a basic snake game in python, give explanations for each step."
            },
            {
                "title": "Assist in a task",
                "prompt": "How do I make a delicious lemon cheesecake?"
            }
        ]
    },
    {
        "name": "meta-llama/Llama-2-70b-chat-hf",
        "displayName": "ü§ó Llama 2 70B Chat",
        "description": "The latest and biggest model from Meta, fine-tuned for chat.",
        "websiteUrl": "https://ai.meta.com/llama/",
        "userMessageToken": "",
        "userMessageEndToken": " [/INST] ",
        "assistantMessageToken": "",
        "assistantMessageEndToken": " </s><s>[INST] ",
        "preprompt": " ",
        "chatPromptTemplate": "<s>[INST] <<SYS>>\n{{preprompt}}\n<</SYS>>\n\n{{#each messages}}{{#ifUser}}{{content}} [/INST] {{/ifUser}}{{#ifAssistant}}{{content}} </s><s>[INST] {{/ifAssistant}}{{/each}}",
        "promptExamples": [
            {
                "title": "Write an email from bullet list",
                "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
            },
            {
                "title": "Code a snake game",
                "prompt": "Code a basic snake game in python, give explanations for each step."
            },
            {
                "title": "Assist in a task",
                "prompt": "How do I make a delicious lemon cheesecake?"
            }
        ],
        "parameters": {
            "temperature": 0.1,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "top_k": 50,
            "truncate": 3072,
            "max_new_tokens": 1024
        }
    },
    {
        "name": "codellama/CodeLlama-34b-Instruct-hf",
        "displayName": "ü§ó CodeLlama 34B Instruct",
        "description": "Code Llama, a state of the art code model from Meta.",
        "websiteUrl": "https://about.fb.com/news/2023/08/code-llama-ai-for-coding/",
        "userMessageToken": "",
        "userMessageEndToken": " [/INST] ",
        "assistantMessageToken": "",
        "assistantMessageEndToken": " </s><s>[INST] ",
        "preprompt": " ",
        "chatPromptTemplate": "<s>[INST] <<SYS>>\n{{preprompt}}\n<</SYS>>\n\n{{#each messages}}{{#ifUser}}{{content}} [/INST] {{/ifUser}}{{#ifAssistant}}{{content}} </s><s>[INST] {{/ifAssistant}}{{/each}}",
        "promptExamples": [
            {
                "title": "Fibonacci in Python",
                "prompt": "Write a python function to calculate the nth fibonacci number."
            },
            {
                "title": "JavaScript promises",
                "prompt": "How can I wait for multiple JavaScript promises to fulfill before doing something with their values?"
            },
            {
                "title": "Rust filesystem",
                "prompt": "How can I load a file from disk in Rust?"
            }
        ],
        "parameters": {
            "temperature": 0.1,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "top_k": 50,
            "truncate": 4096,
            "max_new_tokens": 4096
        }
    },
    {
        "name": "mistralai/Mistral-7B-Instruct-v0.2",
        "displayName": "ü§ó Mistral 7B Instruct v0.2",
        "description": "Mistral 7B is a new Apache 2.0 model, released by Mistral AI that outperforms Llama2 13B in benchmarks.",
        "websiteUrl": "https://mistral.ai/news/announcing-mistral-7b/",
        "preprompt": "",
        "chatPromptTemplate": "<s>{{#each messages}}{{#ifUser}}[INST] {{#if @first}}{{#if @root.preprompt}}{{@root.preprompt}}\n{{/if}}{{/if}} {{content}} [/INST]{{/ifUser}}{{#ifAssistant}}{{content}}</s> {{/ifAssistant}}{{/each}}",
        "parameters": {
            "temperature": 0.3,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "top_k": 50,
            "truncate": 3072,
            "max_new_tokens": 1024,
            "stop": [
                "</s>"
            ]
        },
        "promptExamples": [
            {
                "title": "Write an email from bullet list",
                "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
            },
            {
                "title": "Code a snake game",
                "prompt": "Code a basic snake game in python, give explanations for each step."
            },
            {
                "title": "Assist in a task",
                "prompt": "How do I make a delicious lemon cheesecake?"
            }
        ]
    },
    {
        "name": "TheBloke/Mistral-7B-Instruct-v0.2-GGUF",
        "displayName": "üè† Mistral 7B Instruct v0.2",
        "description": "Locally served Ollama model",
        "chatPromptTemplate": "<s>{{#each messages}}{{#ifUser}}[INST] {{#if @first}}{{#if @root.preprompt}}{{@root.preprompt}}\n{{/if}}{{/if}} {{content}} [/INST]{{/ifUser}}{{#ifAssistant}}{{content}}</s> {{/ifAssistant}}{{/each}}",
        "parameters": {
            "temperature": 0.2,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "top_k": 50,
            "truncate": 3072,
            "max_new_tokens": 1024,
            "stop": [
                "[/s]"
            ]
        },
        "endpoints": [
            {
                "type": "ollama",
                "url": "http://192.168.41.240:11434",
                "ollamaName": "mistral"
            }
        ]
    },
    {
        "name": "TheBloke/OpenHermes-2.5-Mistral-7B-GGUF",
        "displayName": "üè† OpenHermes 7B v2.5",
        "description": "Locally served Ollama model",
        "chatPromptTemplate": "{{#if @root.preprompt}}<|im_start|>system\n{{@root.preprompt}}<|im_end|>\n{{/if}}{{#each messages}}{{#ifUser}}<|im_start|>user\n{{content}}<|im_end|>\n<|im_start|>assistant\n{{/ifUser}}{{#ifAssistant}}{{content}}<|im_end|>\n{{/ifAssistant}}{{/each}}",
        "parameters": {
            "temperature": 0.2,
            "max_new_tokens": 1024
        },
        "endpoints": [
            {
                "type": "ollama",
                "url": "http://192.168.41.240:11434",
                "ollamaName": "openhermes"
            }
        ]
    },
    {
        "name": "TristanBehrens/Phoenix-GGUF",
        "displayName": "üè† Phoenix 7B v2.5",
        "chatPromptTemplate": "<|system|>\n{{preprompt}}</s>\n{{#each messages}}{{#ifUser}}<|user|>\n{{content}}</s>\n<|assistant|>\n{{/ifUser}}{{#ifAssistant}}{{content}}</s>\n{{/ifAssistant}}{{/each}}",
        "description": "Locally served Ollama model",
        "parameters": {
            "temperature": 0.2,
            "max_new_tokens": 1024
        },
        "endpoints": [
            {
                "type": "ollama",
                "url": "http://localhost:11434",
                "ollamaName": "phoenix"
            }
        ]
    }
]